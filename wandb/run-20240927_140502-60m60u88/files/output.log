Batch 10 loss: 0.005342980265617371
Batch 20 loss: 0.00476600643992424
Batch 30 loss: 0.0044957736134529115
Batch 40 loss: 0.004253306806087494
Batch 50 loss: 0.003866262048482895
Batch 60 loss: 0.0036045049130916597
Batch 70 loss: 0.0030501983761787414
Batch 80 loss: 0.0029757207185029983
Batch 90 loss: 0.0028140462413430213
Batch 100 loss: 0.002472514897584915
Batch 110 loss: 0.0024374880194664
Batch 120 loss: 0.002043726682662964
Batch 130 loss: 0.0018209371762350202
Batch 140 loss: 0.002003493018448353
Batch 150 loss: 0.0016639835145324468
Batch 160 loss: 0.0021430555880069735
Batch 170 loss: 0.0015162601051852108
Batch 180 loss: 0.001486965600401163
Batch 190 loss: 0.0012818850502371788
Batch 200 loss: 0.0011845753891393542
Batch 210 loss: 0.0010038719847798346
Batch 220 loss: 0.0009857269367203117
Batch 230 loss: 0.0010308840163052082
Batch 240 loss: 0.0010572215002030135
Batch 250 loss: 0.0008405359648168087
Batch 260 loss: 0.0006967375599779189
Batch 270 loss: 0.0006955643964465707
Batch 280 loss: 0.0006433715699240565
Batch 290 loss: 0.0007334470530040562
Batch 300 loss: 0.0005523538207635283
Batch 310 loss: 0.0005211913455277681
Batch 320 loss: 0.0005539742056280374
Batch 330 loss: 0.000520657230168581
Batch 340 loss: 0.0004900409318506718
Batch 350 loss: 0.0006472531110048294
Batch 360 loss: 0.0005785718411207199
Batch 370 loss: 0.00038319741119630633
Batch 380 loss: 0.0003625003327615559
Batch 390 loss: 0.00042550863232463596
Batch 400 loss: 0.00039247602998511866
Batch 410 loss: 0.0003013769559911452
Batch 420 loss: 0.00023785945211420766
Batch 430 loss: 0.00029830241011222827
Batch 440 loss: 0.00027641180781211007
[INFO] Not enough data, proceeding...
Epoch Done
[INFO] Not enough data, proceeding...
Loss train 0.00027641180781211007, validation 0.030832737684249878
Batch 10 loss: 0.00028138956055045127
[INFO] Not enough data, proceeding...
